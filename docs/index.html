<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<style>
  body {
    padding: 100px;
    width: 1000px;
    margin: auto;
    text-align: left;
    font-weight: 300;
    font-family: 'Open Sans', sans-serif;
    color: #121212;
  }
  h1, h2, h3, h4 {
    font-family: 'Source Sans Pro', sans-serif;
  }
</style>
<title>CS 184 Mesh Editor</title>
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<link href="https://fonts.googleapis.com/css?family=Open+Sans|Source+Sans+Pro" rel="stylesheet">
</head>


<body>

<h1 align="middle">CS 184: Computer Graphics and Imaging, Spring 2019</h1>
<h1 align="middle">Project 3: Pathtracer</h1>
<h2 align="middle">Jireh Wei En Chew, CS184-agu</h2>

<br><br>

<div>

<h1 align="middle">Overview</h2>
<p>Overview</p>


<h2 align="middle">Part 1: Ray Generation and Scene Intersection</h3>
<p>Using the <i>ns_aa</i> argument, we decided which part of the current pixel being raytraced
   we would shoot a ray through. If only 1 ray was used, we would take the centre of the pixel
  and use the provided <i>est_radiance_global_illumination</i> method to obtain the radiance of the ray.
<br>
If not, we would randomly pick <i>ns_aa</i> number of rays and average the samples we got.

<br><br>
In generating the rays, we performed the following calculations to find our ray in world space:
<ol>
  <li>
    Interpolated between the (0,0) and (1,1) positions of in camera space using the random x and y 
    values given in the section above. <br>
    The z value was kept at -1 as the sensor plane was at z = -1.
  </li>
  <li>
    Normalized the vector to ensure it was at unit length.
  </li>
  <li>
    Used <i>c2w</i> multiplication vector to transform the camera space coordinates to world space
     coordinates.
  </li>
  <li>
    Created a ray with the position starting at the camera position <i>pos</i> and direction of the 
    calculated world space ray above.
  </li>
  <li>
    Set the ray's minimum and maximum cast distance to the near and far clipping planes of the camera.
  </li>
</ol>

<br><br>

In order to render triangles and spheres, we implemented methods to calculate for the intersection 
of rays on such objects.

<ul>
  <li>
    Intersecting triangles (Möller Trumbore Algorithm):
    <ol>
      <li>
        We use the Möller Trumbore algorithm to calculate our barycentric coordinates for the point
         on the plane using the 3 vertices of the triangle.
      </li>
      <li>
        In more detail, we make use of Cramer's rule to find the solutions for the 
        barycentric representation of the
         point equated with the equation of the ray.
      </li>
      <li>
        We then check if the barycentric coordinates lie inside the triangle using the test we 
        implemented in Project 1.
      </li>
      <li>
        We check the β and γ values such that they lie within the 0 to 1 range (inclusive). 
      </li>
      <li>
        We also check the α value (representing t in the ray equation) such that it lies between 
        the minimum and maximum t value of the ray.
      </li>
      <li>
        Lastly, to improve performance, we limit the maximum t value to this value of α if all these tests pass
         since the ray cannot pass through to triangles beyond this point.
      </li>
      <li>
        Additionally, we also fill <i>isect</i> with the necessary information about the intersection.
      </li>
    </ol>
  </li>
  <li>
    Intersecting spheres: Solving squares
    <ol>
      <li>
        Solving for intersection with a sphere is simpler and we use the equation of the 
        sphere and equate that to the ray equation.
      </li>
      <li>
        On simplifying, we get a quadratic equation which we can then complete the square.
      </li>
      <li>
        We calculate the determinant first. Upon a negative determinant, we return false as there is no intersection.
      </li>
      <li>
        If it is 0, we set <i>t1</i> and <i>t2</i> to be both -b/2a and return true.
      </li>
      <li>
        If not, we calculate both <i>t1</i> and <i>t2</i> and set <i>t1</i> to be the smaller value and return true.
      </li>
      <li>
        Similarly to the triangle intersection, we limit the maximum t value of the ray to be the t value at the intersection point.
      </li>
      <li>
        We also fill <i>i</i>, the <i>Intersection</i> with the appropriate values.
      </li>
      </li>
    </ul>
  </li>
</ol>
</p>

<div align="middle">
    <table style="width=100%">
      <tr>
        <td>
          <img src="images/Spheres .37s.png" align="middle" width="400px"/>
          <figcaption align="middle">Rendering of spheres: .37 seconds</figcaption>
        </td>
        <td>
            <img src="images/Gems 3.8s.png" align="middle" width="400px"/>
            <figcaption align="middle">Rendering of gems: 3.8 seconds</figcaption>
          </td>
      </tr>
      <br>
      <tr>
        <td>
          <img src="images/Cow 94s.png" align="middle" width="400px"/>
          <figcaption align="middle">Rendering of cow: 94 seconds</figcaption>
        </td>
        <td>
            <img src="images/Coil 147s.png" align="middle" width="400px"/>
            <figcaption align="middle">Rendering of coil: 147 seconds</figcaption>
          </td>
      </tr>
    </table>
  </div>

<br><br>
<h2 align="middle">Part 2: Bounding Volume Hierarchy</h3>

<p>The BVH construction algorithm uses a recursive function to partition the primitives of the mesh 
  into leaves of a binary tree. When scanning for intersections with objects, we use this precomputed 
  information to speed up checking for intersections.

  These are the following steps for generating our BVH tree.
  <ol>
    <li>
      At the start, this algorithm is performed on the root node, and the list of pointers to primitives 
      is the full list of primitives.
    </li>
    <li>
      Cycle through every primitive and create a bounding box for all primitives.
    </li>
    <li>
      Create a new node with this bounding box.
    </li>
    <li>
      Check if the size of the number of primitives is less than the <i>max_leaf_size</i>. If so, we 
      treat this node as a leaf node and assign all the primtives to the <i>node->prims</i> variable of the 
      node we created, and return it.
    </li>
    <li>
      If it is not a leaf node, then we have to partition the primitives into the left and right subtrees.
    </li>
    <li>
      Calculate, based on the size of the bounding box, the largest axis to split the current volume on.
    </li>
    <li>
      We use a heuristic based on the average centroid of all the primitives, and partition the list of primitives 
      based comparing on the largest axis we found. We separate the primitives into a <i>left</i> or <i>right</i> list.
    </li>
    <li>
      If either list is empty, we take one primitive off the other list and push it into the empty list.
      This prevents infinite recursion on an empty list.
    </li>
    <li>
      We recurse with the left and the right list and set <i>node->l</i> and <i>node->r</i> to the resulting node.
    </li>
    <li>
      Finally, we return the node.
    </li>
  </ol>

  The BVH intersection algorithm has 2 versions, one that returns information about the intersection and another
  that just returns true if there is an intersection. This is a recursive algorithm that traverses the BVH tree
  structure we created above.

  <ol>
    <li>
      First, check if the ray intersects the bounding box of the node. For the root node, this is the bounding box of the 
      entire mesh. Return false if it doesn't intersect.
    </li>
    <li>
      If intersects, we check if the ray falls between the t values that intersect the bounding box. Return false if it doesn't.
    </li>
    <li>
      Next, check if the node is a leaf node. If it is, cycle through all primitives and check if the ray intersects with any primitive. 
      Return immediately if true. <br>
      If it's the second version, store a boolean for intersection and return it after cycling through every primitive. This is done so that the nearest
       intersection will be stored, since the primitive intersection function culls all intersections beyond the current one. 
    </li>
    <li>
      If it's not a leaf node, recurse and call the function on the left and right child of the node and returns if there is any intersection.
    </li>
  </ol>
</p>

<div align="middle">
  <table style="width=100%">
    <tr>
      <td>
        <img src="images/Dragon .25s.png" align="middle" width="400px"/>
        <figcaption align="middle">Rendering of dragon: .25 seconds</figcaption>
      </td>
      <td>
          <img src="images/Lucky .24s.png" align="middle" width="400px"/>
          <figcaption align="middle">Rendering of Lucy: .24 seconds</figcaption>
        </td>
    </tr>
    <br>
    <tr>
      <td>
        <img src="images/Beast .19s.png" align="middle" width="400px"/>
        <figcaption align="middle">Rendering of beast: .19 seconds</figcaption>
      </td>
      <td>
          <img src="images/Bunny .29s.png" align="middle" width="400px"/>
          <figcaption align="middle">Rendering of bunny: .29 seconds</figcaption>
        </td>
    </tr>
  </table>
</div>
<br>

<h3><b>Comparing speeds</b></h3>

<p>In part 1, cow.dae took 94s to render. Now, it takes 0.22s. The overhead for building the BVH is only 
  0.0052s, so the overhead for generating the BVH is insignificant compared to the improvements in speed.
  This is in part enabled by the axis-aligned bounding boxes that reduce the amount of multiplications and 
  divisions needs to calculate t values for the ray. In <i>BBox::intersect</i>, we perform a total of 6 subtractions 
  and 6 divisions to determine if a ray intersects a box. Compared to the 3 subtractions, 6 multiplications and 
  1 division to determine intersection at just a general plane , this saves a lot of compute. If we use better heuristics 
  like the surface area heuristic in the lecture note, we will get even better partitions (if we multiply by 6, to check for general 
  bounding boxes, this is a lot more). However, due to time
   limitations, I was only able to use the average centroid position as a splitpoint. 
</p>
<br><br>
<h2 align="middle">Part 3: Direct Illumination</h3>

<p>For an overview, <i>estimate_direct_lighting_hemisphere</i> takes rays from the camera, shoots it into the scene and
generates a random ray from the point of contact, and then samples the light from the intersect of that random ray. If it 
hits a light source, the point will get lit by the light source. However, since this is a random ray, and if there are limited 
number of light sources for the ray to hit, this results in a lot of the scene having darker spots and noise.

<br>
Specific implementation details:
<ol>
  <li>
    Calculate the hit point of the ray from the camera.
  </li>
  <li>
    Convert that into an "outgoing" ray as that is the outgoing direction of the light back towards the camera.
  </li>
  <li>
    Sampling over the number of lights in the scene multiplied by the number of samples to take per light source, we intiate a for loop over <i>num_samples</i>.
    <ol>
      <li>Take a random sample over a hemiphere.</li>
      <li>Convert that sample into world space.</li>
      <li>Create a ray shooting outward in this direction, originating from the point where the camera ray hits an object (let this be <i>CameraObject</i>) in the scene.</li>
      <li>If the ray intersects something, we get the emission of the object. For non-light objects, this is 0.</li>
      <li>Weight the sample by the bsdf of the <i>CameraObject</i>, the cosine of the sample and the pdf.</li>
      <li>Add this to <i>L_out</i>over the total number of samples.</li>
    </ol>
  </li>
  <li>Finally, return <i>L_out</i> divided by the number of samples taken to get the average lightning on the point on the <i>CameraObject</i>.</li>
</ol>

<br>

For <i>estimate_direct_lighting_importance</i> we reverse the process in that we shoot rays from the light towards objects, and collect those that end up hitting objects and 
boucing towards the camera. This allows us to eliminate the noise since we are selecting the rays that will definitely light up the scene, rather than in hemisphere sampling where we
randomly sample and hope to hit the light.

<br>
Specific implementation details:
<ul>
  <li>
    Sampling over the number of lights in the scene we intiate a for loop.
    <ol>
    For delta (point) lights:
      <li>Take a sample of the radiance of the light, while getting the direction of the light 
        to the object we are testing, the distance to this light from the <i>CameraObject</i> ray hit point, and the pdf value. </li>
      <li>Convert the direction to the object coordinate space</li>
      <li>If the z value is less than 0, this means the direction is pointing behind the surface and we can ignore this intersection.</li>
      <li>If it isn't, we create a ray from the hit point to the light and limit the t value to the distance to the light.</li>
      <li>We check if this ray intersects any object with <i>bvh->intersect</i>. If it does, this means the hit point is obscured from the light by 
        something and we can ignore the light contribution from this light.</li>
      <li>Weight the light sample by the bsdf of the point on the <i>CameraObject</i>, the cosine of the direction and divide by the pdf.</li>
      <li>If it doesn't intersect, this point has a direct line of sight to the light and we add the weighted light sample to <i>L_out</i>.</li>
    </ol>
    For area lights:
    <ol>
      We create another for loop for the number of samples per area light.
      <li>
        Similarly to the direct light, we perform the above steps.
      </li>
      <li>However, we accumulate the light samples we get over the for loop, and 
        divide by the number of samples per area light to average over them.
      </li>
      <li> We then add this average to <i>L_out</i>. </li>
    </ol>
  </li>
  <li>Finally, return <i>L_out</i></i>.</li>
</ul>
</p>
<br>
<br>
<h3>Comparison between importance and hemisphere sampling</h3>
<p>Here, we can compare the differences between hemisphere and importance sampling. For the bunny,
  we see that hemisphere sampling is a lot noisier due to the randomness in starting from the hit point on the object 
  and randomly shooting a ray to hit a light. However, with importance sampling, we say that we only want rays from the lights 
  that hit the point that the camera rays hit, hence we eliminate randomness in the sense that we make sure every sample will only accumulate 
  samples from lights. This is also why the dragon appears black in hemisphere sampling, as the light source is a point, and 
  there is a very very low chance that a random ray will hit this point light. However, in importance sampling, we make sure that all rays we sample first hit the 
  point light, then we calculate the light hitting the hit point on the <i>CameraObject</i>.
</p>

<div align="middle">
  <table style="width=100%">
    <tr>
      <td>
        <img src="images/Part3_CBbunny_hemisphere.png" align="middle" width="400px"/>
        <figcaption align="middle">Hemisphere sampling: Bunny is noisy.</figcaption>
      </td>
      <td>
          <img src="images/Part3_CBbunny_importance.png" align="middle" width="400px"/>
          <figcaption align="middle">Importance sampling: Bunny is quiet.</figcaption>
        </td>
    </tr>
    <br>
    <tr>
      <td>
        <img src="images/Part3_dragon_hemisphere.png" align="middle" width="400px"/>
        <figcaption align="middle">Hemisphere sampling: Hidden Dragon</figcaption>
      </td>
      <td>
          <img src="images/Part3_dragon_importance.png" align="middle" width="400px"/>
          <figcaption align="middle">Importance sampling: Crouching Tig- I mean, you can see him now!</figcaption>
        </td>
    </tr>
  </table>
</div>

<br>
<h3>Comparing number of light rays</h3>

<p>We use the CBspheres_lambertian.dae scene to render the images below with varying number of light rays from 
  1, 4, 16 and 64, and keep the number of samples per pixel to 1. We can see having more light rays allow for less noisy pictures.
</p>

<div align="middle">
    <table style="width=100%">
      <tr>
        <td>
          <img src="images/Part3_spheres_ray1_samples1.png" align="middle" width="400px"/>
          <figcaption align="middle">A single light ray.<br>1 light ray.</figcaption>
        </td>
        <td>
            <img src="images/Part3_spheres_ray4_samples1.png" align="middle" width="400px"/>
            <figcaption align="middle">The light rays are multiplying!<br>4 light rays.</figcaption>
          </td>
      </tr>
      <br>
      <tr>
        <td>
          <img src="images/Part3_spheres_ray16_samples1.png" align="middle" width="400px"/>
          <figcaption align="middle">Wait, these aren't bunnies, why are there so many?<br>16 light rays.</figcaption>
        </td>
        <td>
            <img src="images/Part3_spheres_ray64_samples1.png" align="middle" width="400px"/>
            <figcaption align="middle">Oh, light rays are mathematical bunnies.<br> At least they aren't that noisy. 64 light rays.</figcaption>
          </td>
      </tr>
    </table>
  </div>

<h2 align="middle">Part 4: Global Illumination</h2>

<p>The indirect lighting function allows us to include bounced rays of light on shadowy areas. Previously, we
  only looked at points that were in direct line of sight of the light sources. However, non-light sources also reflect light, 
  and these reflected light rays can light up areas otherwise not in line of sight to light sources.
  <br>
  Implementation details:
  <ul>
    Using our importance and hemisphere lighting functions from part 3, we create a recursive function to simulate rays of light boucing around the scene.
    <li>
      In <i>zero_bounce_radiance</i>, we take only the emission of the object itself. For non-light sources, this will be zero.
    </li>
    <li> In <i>one_bounce_radiance</i>, we use our direct lighting function to return samples for objects that are directly in line of sight of the light sources.</li>
   <li>In <i>raytrace_pixel</i>, we set the max depth of the ray to <i>max_ray_depth</i>. This allows us to limit the number of bounces the ray performs.</li>
    <li>
      In <i>at_least_one_bounce_radiance</i>, we perform the following steps recursively:
      <ol>
        <li>Calculate the hit point at which a ray hits an object.</li>
        <li>Convert the incoming ray direction to an outgoing direction.</li>
        <li>Get the radiance for one bounce of light at this point with <i>one_bounce_radiance</i> and get the intersection information.</li>
        <li>Sample the bsdf of the current hit point, as well as the pdf and get a sample of the incoming ray on the intersection</li>
        <li>If the max_ray_depth is 1 or 0, we can just return the radiance of one bounce.</li>
        <li>Else, we probabilistically perform a bounce with 0.7 chance of bouncing. </li>
        <li>Ensure that there is at least one bounce if we have <i>max_ray_depth</i> set to anything above 1 
          by checking the current ray's depth. If it is equal to the <i></i>max_ray_depth</i>, we perform a bounce anyway
        regardless of what the coinflip says.</li>
        <li>Convert the incoming ray to world space.</li>
        <li>Create a bounce ray in the direction of the incoming ray, and a ray depth of one less than the ray that was given as an argument.</li>
        <li>Check if the ray intersects with an object in the scene with <i>bvh->intersect</i>.</li>
        <li>If it does, we get the sample at that point by recursively calling <i>at_least_one_bounce_radiance</i>.</li>
        <li>Weight this sample by the bsdf found, the cosine of the incoming ray and the pdf, as well as the probability of not terminating.</li>
        <li>Add this to <i>L_out</i> and return it.</li>
      </ol>
    </li>
  </ul>
</p>

<h3>Comparing only direct illumination versus only indirect illumination</h3>


<div align="middle">
    <table style="width=100%">
      <tr>
        <td>
          <img src="images/Part4_bunny_1024_directonly.png" align="middle" width="400px"/>
          <figcaption align="middle">A sad, dark bunny lit.<br>Lit by only direct lighting.</figcaption>
        </td>
        <td>
            <img src="images/Part4_spheres_1024_directonly.png" align="middle" width="400px"/>
            <figcaption align="middle">Even sadder, darker spheres.<br>Also only direct lighting.</figcaption>
          </td>
      </tr>
      <tr>
        <td>
          <img src="images/Part3_spheres_ray16_samples1.png" align="middle" width="400px"/>
          <figcaption align="middle">Wait, these aren't bunnies, why are there so many?</figcaption>
        </td>
        <td>
            <img src="images/Part3_spheres_ray64_samples1.png" align="middle" width="400px"/>
            <figcaption align="middle">Oh, light rays are mathematical bunnies. At least they aren't that noisy.</figcaption>
          </td>
      </tr>
    </table>
  </div>
<br><br>

<h3>CBbunny.dae max ray depth comparison</h3>

<div align="middle">
    <table style="width=100">
      <tr>
        <td>
          <img src="images/CBbunny_1024_m0.png" align="middle" width="400px"/>
          <figcaption align="middle">Bunnies <i>AND</i> multiplying light rays?<br>Depth of 0.</figcaption>
        </td>
        <td>
            <img src="images/CBbunny_1024_m1.png" align="middle" width="400px"/>
            <figcaption align="middle">It's an epidemic!<br> Depth of 1.</figcaption>
          </td>
      </tr>
      <br>
      <tr>
        <td>
          <img src="images/CBbunny_1024_m2.png" align="middle" width="400px"/>
          <figcaption align="middle">At least more light rays make the bunnies look better.<br>
          Depth of 2.</figcaption>
        </td>
        <td>
            <img src="images/CBbunny_1024_m3.png" align="middle" width="400px"/>
            <figcaption align="middle">Oh, light rays are mathematical bunnies. At least <br>they aren't that noisy. Depth of 3.</figcaption>
          </td>
      </tr>
      
    </table>
  </div>
<div align="middle">
    <tr>
        <td>
          <img src="images/CBbunny_1024_m100.png" align="middle" width="600px"/>
          <figcaption align="middle">Now this bunny is <i>LIT</i>. <br>100 ray depth.</figcaption>
        </td>
      </tr>
</div>
  

<h2 align="middle">Part 5: Adaptive Sampling</h2>

<p>Since we have implemented indirect lighting, we are able to bounce many rays and get 
  semi-realistic lighting. However, for parts of a scene, sometimes the bounces of light 
  are not needed as the subsequent rays do not significantly change the value of the irradiance on 
  that point. As such, we turn to adapative sampling to check if the value has converged.

Implementation details in <i>raytrace_pixel</i>:
<ol>
  <li>If we have multiple camera rays per pixel, we initialise a running sum of the illumination
     from <i>est_radiance_global_illumination</i> as <i>illumSum</i> or s1 in the spec.</li>
  <li>Initialise a square sum of illumination to calculate our variance in <i>squaredIllumSum</i>, or s2 as specified in the spec.</li>
  <li>Initialise a counter for the number of samples</li>
  <li>For every sample, we add the illumination and squared illumination to these variables. We also increment the number of samples taken by 1.</li>
  <li>Every <i>samplesPerBatch</i> number of samples, we calculate the mean and variable of the set of samples.</li>
  <li>Use these values to calculate the convergence value of the set of samples.</li>
  <li>If this convergence is less than or equal to the percentage tolerance of the mean, we break out of the loop.</li>
  <li>We set the number of samples to the <i>sampleCountBuffer</i>.</li>
  <li>Return the sum of samples averaged over the number of samples, rather than over the max of <i>ns_aa</i>.</li>
</ol></p>

<div align="middle">
    <table style="width=100">
      <tr>
        <td>
          <img src="images/Part_5_bunny_4096_samples_depth_5.png" align="middle" width="400px"/>
          <figcaption align="middle">Very quiet bunny. <br>CBbunny.dae with 4096 samples per pixel and depth of 5.</figcaption>
        </td>
        <td>
            <img src="images/Part_5_bunny_4096_samples_depth_5_rate.png" align="middle" width="400px"/>
            <figcaption align="middle">The ambient occlusion at the corners and edges <br>have more bounces. Like the bunny.</figcaption>
        </td>
    </table>
  </div>

</body>
</html>
